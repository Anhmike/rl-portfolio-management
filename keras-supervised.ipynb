{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:44.420234Z",
     "start_time": "2017-08-06T07:46:43.470694Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__main__ logger started.\n"
     ]
    }
   ],
   "source": [
    "# plotting\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# numeric\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "# utils\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "import tempfile\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display\n",
    "from pprint import pprint\n",
    "\n",
    "# logging\n",
    "logger = log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "logging.basicConfig()\n",
    "log.info('%s logger started.', __name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:44.892886Z",
     "start_time": "2017-08-06T07:46:44.425230Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:44.942925Z",
     "start_time": "2017-08-06T07:46:44.896071Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.abspath('.'))\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:45.098451Z",
     "start_time": "2017-08-06T07:46:44.944377Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.environments.portfolio import PortfolioEnv, sharpe, max_drawdown\n",
    "\n",
    "df_train = pd.read_hdf('./data/poloniex_30m.hf',key='train')\n",
    "df_test = pd.read_hdf('./data/poloniex_30m.hf',key='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:45.124412Z",
     "start_time": "2017-08-06T07:46:45.104094Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_length = 50\n",
    "seed = 0\n",
    "asset_names = df_train.columns.levels[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:35:37.557675Z",
     "start_time": "2017-08-06T07:35:37.497717Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:46:52.021616Z",
     "start_time": "2017-08-06T07:46:45.129328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d6c55781ad408597f2368e5e04f43b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(4745, 6, 50, 3) (4745, 6)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "def unison_shuffled_copies(a, b, random_state=0):\n",
    "    assert len(a) == len(b)\n",
    "    np.random.seed(random_state)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def random_shift(x, fraction):\n",
    "    \"\"\"Apply a random shift to a pandas series.\"\"\"\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    m = np.random.uniform(-fraction, fraction, size=x.shape) + 1\n",
    "    return np.clip(x * m, min_x, max_x)\n",
    "\n",
    "def make_samples(df_train, augument=9):\n",
    "    # make a window of X for each step\n",
    "    X = []\n",
    "    for i in tqdm(range(window_length+1, len(df_train))):\n",
    "        data_window = df_train.iloc[i - window_length - 1:i].copy()\n",
    "\n",
    "        # normalise by second to last open price (last will become y)\n",
    "        open = data_window.xs('open', axis=1, level='Price')\n",
    "        data_window = data_window.divide(open.iloc[-2], level='Pair')\n",
    "        data_window = data_window.drop('open', axis=1, level='Price')\n",
    "        obs = np.array([data_window[asset].as_matrix() for asset in asset_names])\n",
    "\n",
    "        X.append(obs)\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "    # split last return off as label\n",
    "    y = X[:,:,-1,0]\n",
    "    X = X[:,:,:-1,:]\n",
    "    \n",
    "    if augument>0:\n",
    "        X_old = X\n",
    "        y_old = y\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(5):\n",
    "            X.append(random_shift(X_old.copy(), augument))\n",
    "            y.append(y_old.copy())\n",
    "        \n",
    "        X=np.concatenate(X)\n",
    "        y=np.concatenate(y)\n",
    "    \n",
    "    X_train, y_train = unison_shuffled_copies(X, y, random_state=seed)\n",
    "    \n",
    "    print(X.shape,y.shape)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = make_samples(df_train[:1000], augument=0.0025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:32:51.177761Z",
     "start_time": "2017-08-06T07:28:21.359Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:47:10.993092Z",
     "start_time": "2017-08-06T07:46:52.026299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, BatchNormalization, Conv1D, InputLayer, Dropout, regularizers, Conv2D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.layers import Input, merge, Reshape\n",
    "from keras.layers import concatenate, Conv2D\n",
    "from keras.regularizers import l2, l1_l2\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:47:11.368541Z",
     "start_time": "2017-08-06T07:47:10.994708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 6, 50, 3)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 6, 48, 2)          20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6, 48, 2)          8         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 1, 20)          1940      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 6, 1, 20)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 1, 1)           21        \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 1, 1)           4         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 2,115\n",
      "Trainable params: 2,069\n",
      "Non-trainable params: 46\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nb_actions=y_train.shape[1]\n",
    "reg=1e-8\n",
    "observation_space = X_train.shape[1:]\n",
    "\n",
    "# Simple CNN model model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=observation_space))\n",
    "# model.add(Reshape(observation_space))\n",
    "model.add(Conv2D(\n",
    "    filters=2,\n",
    "    kernel_size=(1,3),\n",
    "    kernel_regularizer=l2(reg),\n",
    "    activation='elu'\n",
    "))\n",
    "model.add(BatchNormalization()) # lets add batch norm to decrease training time\n",
    "\n",
    "model.add(Conv2D(\n",
    "    filters=20,\n",
    "    kernel_size=(1,window_length-2),\n",
    "    kernel_regularizer=l2(reg),\n",
    "    activation='elu'\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=(1,1),\n",
    "    kernel_regularizer=l2(reg),\n",
    "    activation='elu'\n",
    "))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(\n",
    "    nb_actions, \n",
    "    kernel_regularizer=l2(reg)\n",
    ")) # this adds cash bias\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:32:51.181577Z",
     "start_time": "2017-08-06T07:28:24.767Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-06T07:46:47.328Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('adam',loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-06T07:46:47.331Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=25,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_split=0.15,\n",
    "          callbacks=[]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T07:23:37.750734Z",
     "start_time": "2017-08-06T07:23:37.553479Z"
    }
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3",
   "language": "python",
   "name": "jupyter3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "85px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
