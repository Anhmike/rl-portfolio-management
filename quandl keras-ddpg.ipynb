{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hackthemarket/gym-trading/blob/master/gym_trading/envs/TradingEnv.ipynb\n",
    "\n",
    "TODO:\n",
    "- test data, val data\n",
    "- multiple stocks?\n",
    "- bitcoin data env?\n",
    "    - quandl bter (200 results) bitfinex (26), BCHARTs\n",
    "- finanical metrics e.g. \n",
    "    - http://www.cs.utexas.edu/~ai-lab/pubs/AMEC04-plat.pdf sharpes\n",
    "    - return\n",
    "    - dummy score\n",
    "        - all buy, all hold, all sell\n",
    "        - random etc\n",
    "    - quantopians\n",
    "- add more observational data\n",
    "    - [x] the last few steps - add memmory\n",
    "    - [ ] sentiment? e.g. https://www.quandl.com/data/NS1-FinSentS-Web-News-Sentiment\n",
    "    - [ ] overall stock market e.g. https://www.quandl.com/data/UMICH/SOC4-University-of-Michigan-Consumer-Survey-Index-of-Consumer-Sentiment-Within-Regions\n",
    "- replay https://github.com/matthiasplappert/keras-rl/issues/40\n",
    "- or try openai baseline with tensorflow\n",
    "- model\n",
    "    - cnn\n",
    "    - lstm\n",
    "- unit tests\n",
    "    - env should give poor result with random steps, only buys, only holds\n",
    "    - model should overfit on small amount of data\n",
    "    \n",
    "- [x] pretraining? helps a lot. Lets the keras-rl beat the market by a few percent initially\n",
    " bugs:\n",
    " - [x] seems to be discontinuities causing huge navs e.g. 1e51\n",
    " \n",
    " \n",
    " regression vs classification\n",
    " \n",
    " window length and memory\n",
    " \n",
    " experience replay\n",
    " \n",
    " I used [arXiv:1612.01277](https://arxiv.org/abs/1706.10059) paper a lot for understanding the problem and ideas for model design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-27T10:14:01.147406Z",
     "start_time": "2017-06-27T18:14:01.142926+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:03:04.042640Z",
     "start_time": "2017-07-15T17:03:03.310635+08:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:__main__ logger started.\n"
     ]
    }
   ],
   "source": [
    "# plotting\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# numeric\n",
    "import quandl\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "\n",
    "# utils\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "import pdb\n",
    "import tempfile\n",
    "import logging\n",
    "import time\n",
    "\n",
    "# logging\n",
    "logger = log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "logging.basicConfig()\n",
    "log.info('%s logger started.', __name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:09:14.499539Z",
     "start_time": "2017-07-15T17:09:14.474272+08:00"
    }
   },
   "outputs": [],
   "source": [
    "# reinforcement learning\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, BatchNormalization, Conv1D, InputLayer, Dropout, regularizers, Conv2D, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T07:24:50.874995Z",
     "start_time": "2017-07-12T15:24:50.872400+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:03:23.074963Z",
     "start_time": "2017-07-15T17:03:23.042298+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append(os.path.abspath('.'))\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# from src.callbacks.rl_callbacks import ReduceLROnPlateau, TrainIntervalLoggerTQDMNotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "Day trading over 256 days. We scale and augument the training data.\n",
    "\n",
    "You can see the base environment class [here](https://github.com/openai/gym/blob/master/gym/core.py#L13) and openai's nice docs [here](https://gym.openai.com/docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:03:27.514277Z",
     "start_time": "2017-07-15T17:03:27.479712+08:00"
    }
   },
   "outputs": [],
   "source": [
    "from src.environments.portfolio import PortfolioEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:03:40.344002Z",
     "start_time": "2017-07-15T17:03:39.814516+08:00"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_hdf('./data/poliniex_30m.hf',key='train')\n",
    "env = PortfolioEnv(\n",
    "    df=df_train,\n",
    "    steps=128, \n",
    "    scale=True, \n",
    "    augument=0.0005    \n",
    ")\n",
    "env.seed = 0   \n",
    "\n",
    "df_test = pd.read_hdf('./data/poliniex_30m.hf',key='test')\n",
    "env_test = PortfolioEnv(\n",
    "    df=df_test,\n",
    "    steps=128, \n",
    "    scale=True, \n",
    "    augument=0.00)\n",
    "env_test.seed = 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T01:21:05.703397Z",
     "start_time": "2017-07-12T09:21:05.644167+08:00"
    }
   },
   "source": [
    "## SELU?\n",
    "\n",
    "I tried SELU but it didn't help, It's mean to replace batchnorm and ELU with less parameters\n",
    "there have been varied reports for it [reddit discussion]( https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:03:42.492618Z",
     "start_time": "2017-07-15T17:03:42.468784+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# from keras import backend as K\n",
    "# def selu(x):\n",
    "#     \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n",
    "#     # Arguments\n",
    "#         x: A tensor or variable to compute the activation function for.\n",
    "#     # References\n",
    "#         - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n",
    "#     \"\"\"\n",
    "#     alpha = 1.6732632423543772848170429916717\n",
    "#     scale = 1.0507009873554804934193349852946\n",
    "#     return scale * K.elu(x, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-04T01:42:37.345932Z",
     "start_time": "2017-07-04T09:42:37.328860+08:00"
    },
    "collapsed": true
   },
   "source": [
    "# Model\n",
    "\n",
    "arXiv:1612.01277 indicated that CNN's are just as effective. That's great because I like them, they are fast so I can try more things and see the results faster. So we will be using a CNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:08:32.470130Z",
     "start_time": "2017-07-15T17:08:32.403066+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:07:22.869809Z",
     "start_time": "2017-07-15T17:07:22.847074+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 6, 8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(window_length,)+env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain the Q model as a normal classification problem\n",
    "\n",
    "We can pretrain on a regular (non-rl) classification problem. This might not be as elegant as end-to-end training but it helps with speed. \n",
    "\n",
    "It also helps me quickly test how a model fit's the data (can it overfit, how much does it generalize?). So it's a good sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T09:09:32.682339Z",
     "start_time": "2017-07-15T17:09:32.656728+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augument the data to compensate for the low quantity\n",
    "def random_shift(x, fraction):\n",
    "    min_x, max_x = np.min(x), np.max(x)\n",
    "    m = np.random.uniform(-fraction, fraction, size=x.shape) + 1\n",
    "    c = np.random.uniform(-fraction, fraction, size=x.shape) * x.std()\n",
    "    return np.clip(x * m + c, min_x, max_x)\n",
    "\n",
    "def X_shift(X, fraction):\n",
    "    X = X.copy()\n",
    "    for i in range(X.shape[1]):\n",
    "        x = X[:,:,i]\n",
    "        X[:,:,i] = random_shift(x, fraction)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T10:34:17.352100Z",
     "start_time": "2017-07-15T18:34:17.228730+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 42, 6, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 2016)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 16)                32272     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 6)                 102       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 32,918\n",
      "Trainable params: 32,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "observation_input (InputLayer)   (None, 42, 6, 8)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "action_input (InputLayer)        (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 2016)          0           observation_input[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 2022)          0           action_input[0][0]               \n",
      "                                                                   flatten_27[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_99 (Dense)                 (None, 32)            64736       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_93 (Activation)       (None, 32)            0           dense_99[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_100 (Dense)                (None, 32)            1056        activation_93[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_94 (Activation)       (None, 32)            0           dense_100[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_101 (Dense)                (None, 32)            1056        activation_94[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_95 (Activation)       (None, 32)            0           dense_101[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_102 (Dense)                (None, 1)             33          activation_95[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_96 (Activation)       (None, 1)             0           dense_102[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 66,881\n",
      "Trainable params: 66,881\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, merge\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "# Next, we build a very simple model.\n",
    "actor = Sequential()\n",
    "actor.add(InputLayer(input_shape=(window_length,) + env.observation_space.shape))\n",
    "actor.add(Flatten())\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(16))\n",
    "actor.add(Activation('relu'))\n",
    "actor.add(Dense(nb_actions))\n",
    "actor.add(Activation('softmax'))\n",
    "print(actor.summary())\n",
    "\n",
    "action_input = Input(shape=(nb_actions,), name='action_input')\n",
    "observation_input = Input(shape=(window_length,) + env.observation_space.shape, name='observation_input')\n",
    "flattened_observation = Flatten()(observation_input)\n",
    "x = concatenate([action_input, flattened_observation])\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(32)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1)(x)\n",
    "x = Activation('linear')(x)\n",
    "critic = Model(inputs=[action_input, observation_input], outputs=x)\n",
    "print(critic.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T10:34:23.815873Z",
     "start_time": "2017-07-15T18:34:22.140436+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rl.agents.ddpg.DDPGAgent at 0x7f07b0450438>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rl.agents.ddpg import DDPGAgent\n",
    "from rl.policy import BoltzmannQPolicy, EpsGreedyQPolicy, LinearAnnealedPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "# Get the environment and extract the number of actions.\n",
    "np.random.seed(0)\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "\n",
    "memory = SequentialMemory(limit=1000, window_length=window_length)\n",
    "random_process = OrnsteinUhlenbeckProcess(\n",
    "    size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "agent = DDPGAgent(\n",
    "    nb_actions=nb_actions,\n",
    "    actor=actor,\n",
    "    critic=critic,\n",
    "    critic_action_input=action_input,\n",
    "    random_process=random_process,\n",
    "    memory=memory,\n",
    "    \n",
    "    nb_steps_warmup_critic=100,\n",
    "    nb_steps_warmup_actor=100,    \n",
    "    gamma=.99,\n",
    "    target_model_update=1e-3\n",
    ")\n",
    "agent.compile(Adam(lr=1e-3), metrics=['mse'])\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T10:34:25.201963Z",
     "start_time": "2017-07-15T18:34:25.180724+08:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.callbacks.keras_rl_callbacks import TrainIntervalLoggerTQDMNotebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T21:33:37.137111Z",
     "start_time": "2017-07-15T22:57:38.308601+08:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 900000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 246s - reward: -2.0639e-04   \n",
      "78 episodes - episode_reward: -0.027 [-0.185, 0.110] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.000 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 245s - reward: -2.2035e-04   \n",
      "78 episodes - episode_reward: -0.028 [-0.255, 0.292] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.002 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 241s - reward: 3.2417e-04   \n",
      "78 episodes - episode_reward: 0.042 [-0.183, 5.335] - loss: 0.002 - mean_squared_error: 0.003 - mean_q: 0.000 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 275s - reward: 0.0010   \n",
      "78 episodes - episode_reward: 0.129 [-0.221, 9.350] - loss: 0.004 - mean_squared_error: 0.009 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 271s - reward: -2.1880e-04    ETA: 0s - rew\n",
      "78 episodes - episode_reward: -0.028 [-0.248, 0.161] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 305s - reward: 1.1233e-06   \n",
      "78 episodes - episode_reward: 0.000 [-0.178, 1.062] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.997 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 305s - reward: 7.6975e-04   \n",
      "78 episodes - episode_reward: 0.098 [-0.238, 4.758] - loss: 0.002 - mean_squared_error: 0.005 - mean_q: 0.012 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 310s - reward: 4.7067e-04   \n",
      "79 episodes - episode_reward: 0.059 [-0.251, 6.651] - loss: 0.002 - mean_squared_error: 0.004 - mean_q: 0.014 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: -1.8256e-04   \n",
      "78 episodes - episode_reward: -0.023 [-0.199, 0.207] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 308s - reward: -2.0015e-04   \n",
      "78 episodes - episode_reward: -0.026 [-0.146, 0.064] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 11 (100000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: 5.6647e-04   \n",
      "78 episodes - episode_reward: 0.073 [-0.254, 8.211] - loss: 0.002 - mean_squared_error: 0.005 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 12 (110000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: -1.2790e-04   \n",
      "78 episodes - episode_reward: -0.017 [-0.198, 0.438] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 13 (120000 steps performed)\n",
      "10000/10000 [==============================] - 310s - reward: -1.2215e-04   \n",
      "78 episodes - episode_reward: -0.018 [-0.200, 0.096] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 14 (130000 steps performed)\n",
      "10000/10000 [==============================] - 307s - reward: 7.8952e-04   \n",
      "78 episodes - episode_reward: 0.104 [-0.182, 8.972] - loss: 0.004 - mean_squared_error: 0.007 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 15 (140000 steps performed)\n",
      "10000/10000 [==============================] - 307s - reward: -1.1444e-04   \n",
      "78 episodes - episode_reward: -0.015 [-0.770, 0.383] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.002 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 16 (150000 steps performed)\n",
      "10000/10000 [==============================] - 311s - reward: -1.9351e-04   \n",
      "79 episodes - episode_reward: -0.024 [-0.223, 0.141] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 17 (160000 steps performed)\n",
      "10000/10000 [==============================] - 310s - reward: 0.0012   \n",
      "78 episodes - episode_reward: 0.150 [-0.244, 9.207] - loss: 0.005 - mean_squared_error: 0.009 - mean_q: 0.012 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 18 (170000 steps performed)\n",
      "10000/10000 [==============================] - 310s - reward: -1.7878e-04    ETA: 0s\n",
      "78 episodes - episode_reward: -0.022 [-0.356, 0.235] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.050 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 19 (180000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: 0.0011   \n",
      "78 episodes - episode_reward: 0.139 [-0.150, 6.626] - loss: 0.004 - mean_squared_error: 0.008 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 20 (190000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: 1.6042e-05   \n",
      "78 episodes - episode_reward: 0.002 [-0.176, 1.814] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.016 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 21 (200000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: -1.0386e-04   \n",
      "78 episodes - episode_reward: -0.014 [-0.149, 0.445] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.012 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 22 (210000 steps performed)\n",
      "10000/10000 [==============================] - 309s - reward: -1.2359e-04   \n",
      "78 episodes - episode_reward: -0.015 [-0.345, 0.731] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.003 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 23 (220000 steps performed)\n",
      "10000/10000 [==============================] - 306s - reward: -8.8479e-05    ETA: 0s - reward: -8.8398\n",
      "78 episodes - episode_reward: -0.012 [-0.168, 1.433] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.006 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 24 (230000 steps performed)\n",
      "10000/10000 [==============================] - 308s - reward: -1.0805e-04   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 episodes - episode_reward: -0.014 [-0.143, 0.413] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.004 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 25 (240000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: -1.0241e-04   \n",
      "78 episodes - episode_reward: -0.014 [-0.211, 0.295] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.003 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 26 (250000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: -1.4630e-04   \n",
      "78 episodes - episode_reward: -0.018 [-0.115, 0.319] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 27 (260000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: 2.7261e-04   \n",
      "78 episodes - episode_reward: 0.035 [-0.290, 4.486] - loss: 0.001 - mean_squared_error: 0.001 - mean_q: 0.000 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 28 (270000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -1.7229e-04   \n",
      "78 episodes - episode_reward: -0.021 [-0.264, 0.382] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 29 (280000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: -1.3250e-04   \n",
      "78 episodes - episode_reward: -0.022 [-0.331, 0.328] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 30 (290000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -1.3904e-04   \n",
      "78 episodes - episode_reward: -0.013 [-0.161, 0.116] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.002 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 31 (300000 steps performed)\n",
      "10000/10000 [==============================] - 250s - reward: 0.0012   - ETA: 0s \n",
      "78 episodes - episode_reward: 0.157 [-0.253, 9.114] - loss: 0.006 - mean_squared_error: 0.011 - mean_q: 0.002 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 32 (310000 steps performed)\n",
      "10000/10000 [==============================] - 250s - reward: -1.8848e-04   \n",
      "79 episodes - episode_reward: -0.024 [-0.373, 0.445] - loss: 0.006 - mean_squared_error: 0.013 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.002 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 33 (320000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: -7.9566e-05   \n",
      "78 episodes - episode_reward: -0.010 [-0.150, 0.312] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 34 (330000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: 8.6628e-04   \n",
      "78 episodes - episode_reward: 0.111 [-0.146, 9.847] - loss: 0.005 - mean_squared_error: 0.010 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 35 (340000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: -1.5725e-04   \n",
      "78 episodes - episode_reward: -0.020 [-0.282, 0.324] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 36 (350000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: -1.5033e-04   \n",
      "78 episodes - episode_reward: -0.019 [-0.230, 0.856] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 37 (360000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: 2.7008e-04   \n",
      "78 episodes - episode_reward: 0.035 [-0.171, 3.808] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 38 (370000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: 4.8595e-04   \n",
      "78 episodes - episode_reward: 0.062 [-0.135, 6.289] - loss: 0.003 - mean_squared_error: 0.006 - mean_q: 0.012 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 39 (380000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: -2.0588e-04    E\n",
      "78 episodes - episode_reward: -0.026 [-0.279, 0.408] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 40 (390000 steps performed)\n",
      "10000/10000 [==============================] - 255s - reward: 0.0012   \n",
      "79 episodes - episode_reward: 0.146 [-0.320, 9.557] - loss: 0.005 - mean_squared_error: 0.009 - mean_q: 0.017 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 41 (400000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: -2.8024e-04   \n",
      "78 episodes - episode_reward: -0.036 [-1.003, 0.260] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.014 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 42 (410000 steps performed)\n",
      "10000/10000 [==============================] - 255s - reward: 2.2842e-04   - ETA: 1s -\n",
      "78 episodes - episode_reward: 0.031 [-0.284, 4.100] - loss: 0.001 - mean_squared_error: 0.001 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 43 (420000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: -1.7068e-04    ETA: \n",
      "78 episodes - episode_reward: -0.024 [-0.309, 0.177] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 44 (430000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: -1.4452e-04   \n",
      "78 episodes - episode_reward: -0.019 [-0.160, 0.227] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 45 (440000 steps performed)\n",
      "10000/10000 [==============================] - 255s - reward: -1.8597e-04   \n",
      "78 episodes - episode_reward: -0.023 [-0.639, 0.620] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.004 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 46 (450000 steps performed)\n",
      "10000/10000 [==============================] - 255s - reward: -1.7147e-04   \n",
      "78 episodes - episode_reward: -0.023 [-0.216, 0.332] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.002 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 47 (460000 steps performed)\n",
      "10000/10000 [==============================] - 258s - reward: -1.1064e-04   \n",
      "78 episodes - episode_reward: -0.012 [-0.155, 0.323] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: -0.000 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 48 (470000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 249s - reward: -2.5934e-04   \n",
      "79 episodes - episode_reward: -0.035 [-0.254, 0.161] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 49 (480000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -1.3015e-04   \n",
      "78 episodes - episode_reward: -0.017 [-0.223, 0.366] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.003 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 50 (490000 steps performed)\n",
      "10000/10000 [==============================] - 250s - reward: 1.9390e-04   \n",
      "78 episodes - episode_reward: 0.026 [-0.173, 0.927] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: -0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 51 (500000 steps performed)\n",
      "10000/10000 [==============================] - 247s - reward: -4.6792e-05   \n",
      "78 episodes - episode_reward: -0.007 [-0.294, 0.373] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: -0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 52 (510000 steps performed)\n",
      "10000/10000 [==============================] - 247s - reward: 8.8362e-04   \n",
      "78 episodes - episode_reward: 0.114 [-0.184, 5.755] - loss: 0.002 - mean_squared_error: 0.004 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 53 (520000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: 4.2279e-04   \n",
      "78 episodes - episode_reward: 0.054 [-0.323, 5.816] - loss: 0.002 - mean_squared_error: 0.004 - mean_q: 0.005 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 54 (530000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: 2.2306e-04   \n",
      "78 episodes - episode_reward: 0.029 [-0.207, 2.957] - loss: 0.001 - mean_squared_error: 0.001 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 55 (540000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -1.0078e-04   \n",
      "78 episodes - episode_reward: -0.014 [-0.108, 0.222] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 56 (550000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -3.1549e-04   \n",
      "79 episodes - episode_reward: -0.040 [-0.275, 0.116] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.004 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 57 (560000 steps performed)\n",
      "10000/10000 [==============================] - 250s - reward: 7.2630e-04   \n",
      "78 episodes - episode_reward: 0.093 [-0.199, 9.157] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.001 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 58 (570000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: 5.2455e-04   \n",
      "78 episodes - episode_reward: 0.068 [-0.460, 6.660] - loss: 0.006 - mean_squared_error: 0.011 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 59 (580000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: -6.2829e-05   \n",
      "78 episodes - episode_reward: -0.009 [-0.332, 0.903] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 60 (590000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: -1.1523e-04   \n",
      "78 episodes - episode_reward: -0.014 [-0.315, 0.444] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 61 (600000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: -7.9947e-05   \n",
      "78 episodes - episode_reward: -0.009 [-0.317, 0.204] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.006 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 62 (610000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: 4.3906e-04   \n",
      "78 episodes - episode_reward: 0.055 [-0.353, 4.870] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.008 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 63 (620000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: -9.6117e-05   \n",
      "78 episodes - episode_reward: -0.013 [-0.334, 0.601] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 64 (630000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: 8.6704e-04   \n",
      "79 episodes - episode_reward: 0.110 [-0.417, 6.321] - loss: 0.004 - mean_squared_error: 0.007 - mean_q: 0.013 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 65 (640000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: 3.3548e-04   \n",
      "78 episodes - episode_reward: 0.043 [-0.245, 4.134] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.016 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 66 (650000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: -1.5578e-04   \n",
      "78 episodes - episode_reward: -0.020 [-0.228, 0.253] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.015 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 67 (660000 steps performed)\n",
      "10000/10000 [==============================] - 255s - reward: -3.0199e-05   \n",
      "78 episodes - episode_reward: -0.004 [-0.228, 0.563] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.012 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 68 (670000 steps performed)\n",
      "10000/10000 [==============================] - 256s - reward: -4.8632e-05   \n",
      "78 episodes - episode_reward: -0.006 [-0.201, 1.407] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 69 (680000 steps performed)\n",
      "10000/10000 [==============================] - 254s - reward: 2.7966e-04   \n",
      "78 episodes - episode_reward: 0.036 [-0.156, 4.029] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 70 (690000 steps performed)\n",
      "10000/10000 [==============================] - 256s - reward: 3.8604e-04   \n",
      "78 episodes - episode_reward: 0.049 [-0.470, 6.391] - loss: 0.003 - mean_squared_error: 0.006 - mean_q: 0.014 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 71 (700000 steps performed)\n",
      "10000/10000 [==============================] - 256s - reward: -1.0247e-04   \n",
      "78 episodes - episode_reward: -0.013 [-0.237, 0.278] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.013 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 72 (710000 steps performed)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 245s - reward: 2.2093e-04   \n",
      "79 episodes - episode_reward: 0.027 [-0.164, 4.378] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 73 (720000 steps performed)\n",
      "10000/10000 [==============================] - 245s - reward: -1.7273e-04   \n",
      "78 episodes - episode_reward: -0.022 [-0.174, 0.174] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 74 (730000 steps performed)\n",
      "10000/10000 [==============================] - 247s - reward: -1.4076e-04   \n",
      "78 episodes - episode_reward: -0.018 [-0.178, 0.343] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.006 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 75 (740000 steps performed)\n",
      "10000/10000 [==============================] - 247s - reward: 0.0013   \n",
      "78 episodes - episode_reward: 0.170 [-0.162, 10.344] - loss: 0.003 - mean_squared_error: 0.005 - mean_q: 0.004 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 76 (750000 steps performed)\n",
      "10000/10000 [==============================] - 247s - reward: 4.9826e-04   \n",
      "78 episodes - episode_reward: 0.065 [-0.230, 6.242] - loss: 0.006 - mean_squared_error: 0.012 - mean_q: 0.020 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 77 (760000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: 0.0011   \n",
      "78 episodes - episode_reward: 0.145 [-0.277, 8.379] - loss: 0.005 - mean_squared_error: 0.009 - mean_q: 0.027 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 78 (770000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: -1.5455e-04   \n",
      "78 episodes - episode_reward: -0.021 [-0.190, 0.429] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.024 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 79 (780000 steps performed)\n",
      "10000/10000 [==============================] - 248s - reward: -3.7612e-05   \n",
      "78 episodes - episode_reward: -0.005 [-0.183, 0.301] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.018 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 80 (790000 steps performed)\n",
      "10000/10000 [==============================] - 249s - reward: -1.0749e-04   \n",
      "79 episodes - episode_reward: -0.013 [-0.200, 0.522] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.014 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 81 (800000 steps performed)\n",
      "10000/10000 [==============================] - 250s - reward: -1.6914e-04   \n",
      "78 episodes - episode_reward: -0.021 [-0.210, 0.290] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 82 (810000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: 3.5397e-04   \n",
      "78 episodes - episode_reward: 0.045 [-0.271, 5.485] - loss: 0.002 - mean_squared_error: 0.003 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 83 (820000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: 3.3687e-04   \n",
      "78 episodes - episode_reward: 0.043 [-0.205, 5.780] - loss: 0.001 - mean_squared_error: 0.001 - mean_q: 0.010 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.001 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 84 (830000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: -2.8534e-04   \n",
      "78 episodes - episode_reward: -0.036 [-0.356, 0.273] - loss: 0.002 - mean_squared_error: 0.004 - mean_q: 0.013 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 0.999 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 85 (840000 steps performed)\n",
      "10000/10000 [==============================] - 251s - reward: -1.9479e-04   \n",
      "78 episodes - episode_reward: -0.025 [-0.225, 0.189] - loss: 0.003 - mean_squared_error: 0.005 - mean_q: 0.009 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 86 (850000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: 2.7574e-04   \n",
      "78 episodes - episode_reward: 0.035 [-0.193, 4.721] - loss: 0.001 - mean_squared_error: 0.002 - mean_q: 0.011 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 87 (860000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: -2.0779e-04   \n",
      "78 episodes - episode_reward: -0.027 [-0.171, 0.178] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.007 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 88 (870000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: -1.1235e-04   \n",
      "79 episodes - episode_reward: -0.014 [-0.158, 0.409] - loss: 0.000 - mean_squared_error: 0.001 - mean_q: 0.004 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 89 (880000 steps performed)\n",
      "10000/10000 [==============================] - 252s - reward: -1.4044e-04   \n",
      "78 episodes - episode_reward: -0.018 [-0.134, 0.365] - loss: 0.000 - mean_squared_error: 0.000 - mean_q: 0.002 - log_reward: 0.000 - portfolio_value: 1.000 - returns: 1.000 - rate_of_return: 0.000 - cost: 0.000 - steps: 0.000\n",
      "\n",
      "Interval 90 (890000 steps performed)\n",
      "10000/10000 [==============================] - 253s - reward: 2.0121e-04   \n",
      "done, took 23758.722 seconds\n"
     ]
    }
   ],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "history = agent.fit(env, \n",
    "                  nb_steps=900000, \n",
    "                  visualize=False, \n",
    "                  verbose=1,\n",
    "                  callbacks=[\n",
    "#                       TrainIntervalLoggerTQDMNotebook(),\n",
    "#                       ReduceLROnPlateau(monitor='episode_reward', patience = 150)\n",
    "                    ]\n",
    "                 )\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('outputs/agent_{}_weights.h5f'.format('portfolio-ddpg-keras-rl'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T22:07:19.253027Z",
     "start_time": "2017-07-16T06:07:19.171484+08:00"
    }
   },
   "outputs": [],
   "source": [
    "agent.save_weights('outputs/agent_{}_weights.h5f'.format('portfolio-ddpg-keras-rl'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T14:57:23.732325Z",
     "start_time": "2017-07-15T22:57:23.578361+08:00"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T22:07:25.878062Z",
     "start_time": "2017-07-16T06:07:20.733011+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "Episode 1: reward: 0.024, steps: 128\n",
      "Episode 2: reward: -0.000, steps: 128\n",
      "Episode 3: reward: -0.024, steps: 128\n",
      "Episode 4: reward: -0.311, steps: 128\n",
      "Episode 5: reward: 0.020, steps: 128\n",
      "Episode 6: reward: 0.093, steps: 128\n",
      "Episode 7: reward: -0.097, steps: 128\n",
      "Episode 8: reward: -0.033, steps: 128\n",
      "Episode 9: reward: -0.113, steps: 128\n",
      "Episode 10: reward: -0.065, steps: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0796069630>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env_test, nb_episodes=10, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-15T22:07:28.889416Z",
     "start_time": "2017-07-16T06:07:27.803211+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr0AAALACAYAAACemMrHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIjK3v8P5Bqe3WKxgyMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f079e987da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# history\n",
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist\n",
    "df_hist['episodes'] = df_hist.index\n",
    "\n",
    "g = sns.jointplot(x=\"episodes\", y=\"episode_reward\", data=df_hist, kind=\"reg\", size=10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# g = sns.jointplot(x=\"episodes\", y=\"rewards\", data=history, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualise\n",
    "\n",
    "ideally a price with colored actions? like https://hackernoon.com/the-self-learning-quant-d3329fcc9915"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-01T03:02:19.820742Z",
     "start_time": "2017-07-01T11:02:19.740692+08:00"
    }
   },
   "source": [
    "# dummy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T05:43:10.780067Z",
     "start_time": "2017-07-12T05:42:52.587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T05:43:10.781457Z",
     "start_time": "2017-07-12T05:42:52.589Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_flat = X_train.reshape((len(X_train),-1))\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(X_flat, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "def test_env(env, model, memory):\n",
    "    obs = env.reset()\n",
    "    state = memory.get_recent_state(obs)\n",
    "    for t in range(env.days):\n",
    "        x_batch = np.array([state])\n",
    "        x_flat = x_batch.reshape((len(x_batch),-1))\n",
    "        x_flat[np.isnan(x_flat)]=0\n",
    "        y_pred = model.predict(x_flat)\n",
    "        action = y_pred.argmax(1)\n",
    "        obs, rew, done, info = env.step(action[0])\n",
    "        state = memory.get_recent_state(obs)\n",
    "    \n",
    "    df_test = env.sim.to_df()\n",
    "    end = df_test.iloc[-1]\n",
    "    gain = end.bod_nav - end.mkt_nav    \n",
    "    return gain\n",
    "\n",
    "dummy_scores = []\n",
    "for strategy in ['most_frequent', 'uniform', 'prior', 'stratified']:\n",
    "    memory = Memory(window_length=window_length)\n",
    "    clf = DummyClassifier(strategy=strategy)\n",
    "    clf.fit(X_train, y_train)\n",
    "    gain = test_env(env_test, clf, memory)\n",
    "    df=env_test.sim.to_df()\n",
    "    print('{:20.20s}: {: 3.2%} /day NAV gain above market'.format(strategy, (df.mkt_nav-df.bod_nav).mean()))\n",
    "    \n",
    "    plot_env(env_test, title=strategy)  \n",
    "\n",
    "for strategy in ['mean', 'median']:\n",
    "    memory = Memory(window_length=window_length)\n",
    "    clf=DummyRegressor(strategy=strategy)\n",
    "    clf.fit(X_train, y_train)\n",
    "    gain = test_env(env_test, clf, memory)\n",
    "    df=env_test.sim.to_df()\n",
    "    print('{:20.20s}: {: 3.2%} /day NAV gain above market'.format(strategy, (df.mkt_nav-df.bod_nav).mean()))\n",
    "    \n",
    "    plot_env(env_test, title=strategy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-12T05:43:10.782763Z",
     "start_time": "2017-07-12T05:42:52.591Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_env(env_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3",
   "language": "python",
   "name": "jupyter3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
